<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Abstracts</title>
</head>

<body stylesrc="../program_schedule.htm" bgcolor="#FF9830">

<h1 align="left"><a name="25W"></a><i>The Nature of Scientific Evidence</i>
(Workshop)</h1>
<p>&nbsp;</p>
<h2><a name="25WX"></a><b>Chair</b>&nbsp;&nbsp;&nbsp; <a href="../program_authors.htm#Sober">Elliott
Sober</a> (University of Wisconsin)&nbsp;</h2>
<p>&nbsp;</p>
<h2><a name="25WB"></a><b>&quot;Statistical Evidence, Evidence Functions and the
Concept of Verisimilitude&quot;</b>&nbsp;&nbsp;&nbsp; <a href="../program_authors.htm#Lele">Subhas
R. Lele</a> (University of Alberta)&nbsp;</h2>
<p>Hacking (1965) suggested the law of the likelihood for quantifying the
strength of evidence for one hypothesis over the competing hypothesis. Royall
(1997) developed this concept further and introduced the concepts of probability
of weak and misleading evidence. Although powerful, the likelihood ratio as a
quantification of strength of evidence, suffers from lack of robustness to
outliers in the data. It also requires that the probabilistic model be fully
specified. Another limitation has been that much of the discussion in the
evidence literature has been about comparing simple versus simple hypotheses.</p>
<p>Lele (2002) introduces a class of functions, called the evidence functions,
that looks at strength of evidence as a comparison between discrepancies between
the true model and the two hypotheses. Likelihood ratio is a particular case in
the class of evidence functions. But by considering other discrepancy measures
such as the Hellinger distance, this quantification can be made robust against
outliers. Moreover, Jeffrey's discrepancy measure leads to the Quasi-likelihood
ratio as a valid measure of evidence, thus allowing for quantification of
evidence in semiparametric models. An interesting consequence of the use of
these general evidence functions is that the stopping rule becomes relevant to
the quantification of evidence, vis a vis the likelihood ratio that ignores the
stopping rule.</p>
<p>In this paper, I will discuss above results. Further I will present an
extension of the evidence functions to the situation where one is comparing
composite hypotheses. I will also explore the relationship between the evidence
functions and the concept of verisimilitude introduced by Popper.</p>
<p>&nbsp;</p>
<h2><a name="25WC"></a><b>&quot;Two Approaches Compared: Likelihood and Bayesian
Approaches&quot;</b>&nbsp;&nbsp;&nbsp; <a href="../program_authors.htm#Rosenkrantz">Roger
D. Rosenkrantz</a>  (Independent Scholar)&nbsp;</h2>
<p>We will compare and contrast likelihood and Bayesian approaches to model
assessment.</p>
<p>&nbsp;</p>
<h2><a name="25WD"></a><b>&quot;The Nature of Scientific Evidence: A Forward
Looking Synthesis&quot;</b>&nbsp;&nbsp;&nbsp; <a href="../program_authors.htm#Taper">Mark
L. Taper</a> (Montana State University)&nbsp;</h2>
<p><span style="font-size:11.0pt;mso-bidi-font-size:10.0pt;
font-family:&quot;Times New Roman&quot;;mso-fareast-font-family:&quot;Times New Roman&quot;;
color:black;mso-ansi-language:EN-US;mso-fareast-language:EN-US;mso-bidi-language:
AR-SA">We present our synthesis of the edited volume <i style="mso-bidi-font-style:
normal">The Nature of Scientific Evidence: Empirical, Statistical, and
Philosophical Consideration</i>. We discuss the role of evidence in science,
models as a representation of reality, how data inform us the relationship of
models and reality. We define evidence from the evidential paradigm’s
perspective and distinguish this concept from the concept of evidence in
frequentist and Bayesian statistics. The evidential perspective gives beneficial
insight on a number of the most perplexing inferential problems in statistics,
including model centered inference, multiple comparisons, inference in the
presence of nuisance parameters, <i style="mso-bidi-font-style:normal">a priori</i>
versus <i style="mso-bidi-font-style:normal">post hoc</i> analysis, and causal
inference. Also discussed is the relationship of statistical evidence to
statistical inference.</span></p>
<p>&nbsp;</p>
<h2><a name="25WE"></a><b>&quot;Royall's Three Questions: A Bayesian Reply&quot;</b>&nbsp;&nbsp;&nbsp;
<a href="../program_authors.htm#Bandyopadhyay">Prasanta S. Bandyopadhyay</a>
(Montana State University)&nbsp;</h2>
<p>Royall has discussed three questions, which I call the belief question, the
evidence question and the acceptance question respectively. Royall also argues
that Bayesians could only address the belief question. I consider a Bayesian
proposal that provides a unified account to these three questions. Hence,
Royall's argument against Bayesians is not correct.</p>

</body>

</html>
