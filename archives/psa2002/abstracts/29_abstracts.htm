<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Abstracts</title>
</head>

<body bgcolor="#FF9830">

<h1 align="left"><a name="29"></a><i>Methodology in Practice: Is there a A New Normativity in Philosophy of Science?</i>
 (Symposium)</h1>
<p>Faced with the gaps between an incomplete, noisy, and shaky data base, and a
host of scientific questions, hypotheses, and policies, a panoply of tools has
been developed by social scientists, statisticians, and risk assessors in order
to cope with the limitations and uncertainties (e.g., extrapolation models,
statistical inference, regression and structural equation modeling).
Philosophers of science who immerse themselves in practice, however, have often
discovered that the methods and models routinely used to these ends are mired in
confusion, controversy, and unquestioned assumptions, often along with a
reluctance among practitioners to tinker with already accepted methods. Yet when
methodological disputes emerge in the sciences themselves, the scientific
community seldom looks to philosophy for help in their resolution. Examples
abound: disputes over hypothesis-testing in psychology; disputes over the proper
uses of regression in applied statistics; disputes over does-response curves in
estimating risks, disputes over the use of individual case studies versus
aggregated comparisons of groups in cognitive neuropsychology, and so on. </p>
<p>Drawing upon their research in a variety of fields, each of the contributors
of our symposium will offer distinct, yet interconnected, insights into: </p>
<p>1) the roles that philosophers of science can (and occasionally do) play in
evaluating and instructing scientific methodology in practice; </p>
<p>2) the interrelationships between science policy disputes and disputes about
the acceptability of methodological value judgments and the validity of the
evidence; </p>
<p>3) the relevance of understanding and resolving “practical”
methodological problems for problems in philosophy of science (about data,
experiment, causal inference, model selection, and values in scientific
evidence).</p>
<p>&nbsp;</p>
<h2><a name="29X"></a><b>Chair</b>&nbsp;&nbsp;&nbsp; <a href="../program_authors.htm#Cartwright">Nancy
Cartwright</a> (London School of Economics)&nbsp;</h2>
<p>&nbsp;</p>
<h2><a name="29A"></a><b>&quot;Why Is Philosophy So Useless to Science?&quot;</b>&nbsp;&nbsp;&nbsp;
<a href="../program_authors.htm#Glymour">Clark Glymour</a> (Carnegie Mellon
University)&nbsp;</h2>
<p>Emphasizing the education, fashions and disciplinary habits of philosophers,
I will discuss some of the reasons why very little work in philosophy of science
proves of value to the actual conduct of science, and give examples where it
does or has.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2><a name="29B-1"></a><b>&quot;Model Misspecification in Practice: Philosophy
and Methodology of Testing Assumptions of Statistical Models&quot;</b>&nbsp;&nbsp;&nbsp;
<a href="../program_authors.htm#Mayo">Deborah Mayo</a> (Virginia Tech) and <a href="../program_authors.htm#Spanos">Aris
Spanos</a> (Virginia Tech)&nbsp;</h2>
<p>Increased reliance on statistical models in the social sciences has not been
accompanied by attention to testing the assumptions underlying these models -
Misspecification (M-S) testing. Routinely used M-S tests poorly detect obvious
violations in assumptions, and endorse fallacious ways of accommodating
violations when found. Debates over M-S tests often revolve around philosophical
issues, but philosophers are rarely involved in resolving them. Ironically,
philosophers of science often appeal to model selection techniques in their
work, overlooking questions about model assumptions. A key task is to
distinguish reliable from unreliable methods of 'data snooping' and 'data
mining' in the area of M-S testing. </p>
<p>&nbsp;</p>
<h2><a name="29C"></a><b>&quot;Better Policy through Better Science: Using
Metascience to Improve Dose-Response Curves in Biology&quot;</b>&nbsp;&nbsp;&nbsp;
<a href="../program_authors.htm#Shrader-Frechette">Kristin
Shrader-Frechette</a> (University of Notre Dame)&nbsp;<a href="http://philsci-archive.pitt.edu/documents/disk0/00/00/08/71/index.html" target="_top"><font size="2">[full
text]</font></a></h2>
<p>For the last two years, members of the International Commission on
Radiological Protection (ICRP) have debated the merits of alternative hypotheses
about the shape of the dose-response curve for biological effects of ionizing
radiation. (The author is a member of a major ICRP committee that, within the
next year, will make recommendations to international regulators about the
scientific merits of various hypotheses.) The ICRP controversy is fueled, on the
one hand, by fears of nuclear power and of a repetition of the Chernobyl
accident and, on the other hand, by desires to cut costs in weapons clean-up and
reactor decommissioning. In response to this conflict, many people argue that
uncertain science -- or controversial policies based on science -- can be
clarified primarily by greater attention to the social values influencing the
science and the policy. This paper argues that while such clarification may be
necessary, it is neither a sufficient condition, nor even the primary means, by
which to achieve better science and better policy. Using a case study involving
the current, highly politicized controversy over the shape of dose-response
curves for biological effects of ionizing radiation, the paper argues that the
conflict could be resolved largely through metascience, by getting the science
right. Getting the science right, in this biological case, would mean taking
adequate account of (1) internal and external inconsistencies, (2) poor
predictive power, and (3) false inferences about measurement uncertainties,
associated with one (rather than its main alternative) hypothesis about the
proposed dose-response curve.</p>
<p>&nbsp;</p>
<h2><a name="29D"></a><b>&quot;Philosophy in Practice: Evidence Stabilizing
Technologies in Archaeology&quot;</b>&nbsp;&nbsp;&nbsp; <a href="../program_authors.htm#Wylie">Alison
Wylie</a> (Washington University)</h2>
<p>Archaeologists deal with one of the noisiest and shakiest of data bases, and
they are acutely aware of this; they actively debate the basic assumptions, as
well as more technical problems, associated with standard techniques for
stabilizing evidence. Periodically philosophy of science has been an important
resource in addressing these issues, with mixed results. I argue that, if we are
to play a useful role in adjudicating normative questions about the limitations
and uncertainties of specific research methods, we must be prepared to
transgress the distinctions between epistemic and non-epistemic considerations
that structure much philosophical analysis of science.</p>

</body>

</html>
